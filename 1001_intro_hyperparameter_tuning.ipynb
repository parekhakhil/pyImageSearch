{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1001-intro_hyperparameter_tuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parekhakhil/pyImageSearch/blob/main/1001_intro_hyperparameter_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4RpK9pawQzP"
      },
      "source": [
        "# Introduction to hyperparameter tuning with scikit-learn and Python\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ntZ1AkXZIxY"
      },
      "source": [
        "\n",
        "\n",
        "This notebook is associated with the [Introduction to hyperparameter tuning with scikit-learn and Python](https://www.pyimagesearch.com/2021/05/17/introduction-to-hyperparameter-tuning-with-scikit-learn-and-python/) blog post published on 2021-05-17.\n",
        "\n",
        "Only the code for the blog post is here. Most codeblocks have a 1:1 relationship with what you find in the blog post with two exceptions: (1) Python classes are not separate files as they are typically organized with PyImageSearch projects, and (2) Command Line Argument parsing is replaced with an `args` dictionary that you can manipulate as needed.\n",
        "\n",
        "We recommend that you execute (press ▶️) the code block-by-block, as-is, before adjusting parameters and `args` inputs. Once you've verified that the code is working, you are welcome to hack with it and learn from manipulating inputs, settings, and parameters. For more information on using Jupyter and Colab, please refer to these resources:\n",
        "\n",
        "*   [Jupyter Notebook User Interface](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html#notebook-user-interface)\n",
        "*   [Overview of Google Colaboratory Features](https://colab.research.google.com/notebooks/basic_features_overview.ipynb)\n",
        "\n",
        "\n",
        "Happy hacking!\n",
        "\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFhAzQB3aNMa"
      },
      "source": [
        "### Download the code zip file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y0LG1EuaRlB"
      },
      "source": [
        "!wget https://pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com/intro-hyperparameter-tuning/intro-hyperparameter-tuning.zip\n",
        "!unzip -qq intro-hyperparameter-tuning.zip\n",
        "%cd intro-hyperparameter-tuning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SgTVT3HagGZ"
      },
      "source": [
        "## Blog Post Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcrOk6pURp50"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJaCNlDDRz6d"
      },
      "source": [
        "# import the necessary packages\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPsyzljPySti"
      },
      "source": [
        "### Creating our `Config` class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLeJnNuMyWMJ"
      },
      "source": [
        "class Config:\n",
        "    # specify the path of our dataset\n",
        "    CSV_PATH = \"abalone_train.csv\"\n",
        "\n",
        "    # specify the column names of our dataframe\n",
        "    COLS = [\"Length\", \"Diameter\", \"Height\", \"Whole weight\",\n",
        "        \"Shucked weight\", \"Viscera weight\", \"Shell weight\", \"Age\"]\n",
        "\n",
        "# instantiate an object of the configuration class\n",
        "config = Config()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jppw5-Bd56H-"
      },
      "source": [
        "### Implementing a basic training script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okM7Bpyeq8Kc"
      },
      "source": [
        "# load the dataset, separate the features and labels, and perform a\n",
        "# training and testing split using 85% of the data for training and\n",
        "# 15% for evaluation\n",
        "print(\"[INFO] loading data...\")\n",
        "dataset = pd.read_csv(config.CSV_PATH, names=config.COLS)\n",
        "dataX = dataset[dataset.columns[:-1]]\n",
        "dataY = dataset[dataset.columns[-1]]\n",
        "(trainX, testX, trainY, testY) = train_test_split(dataX,\n",
        "\tdataY, random_state=3, test_size=0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K79CyK5Uyvgy"
      },
      "source": [
        "# standardize the feature values by computing the mean, subtracting\n",
        "# the mean from the data points, and then dividing by the standard\n",
        "# deviation\n",
        "scaler = StandardScaler()\n",
        "trainX = scaler.fit_transform(trainX)\n",
        "testX = scaler.transform(testX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuCITMMhyv2U"
      },
      "source": [
        "# train the model with *no* hyperparameter tuning\n",
        "print(\"[INFO] training our support vector regression model\")\n",
        "model = SVR()\n",
        "model.fit(trainX, trainY)\n",
        "\n",
        "# evaluate our model using R^2-score (1.0 is the best value)\n",
        "print(\"[INFO] evaluating...\")\n",
        "print(\"R2: {:.2f}\".format(model.score(testX, testY)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkv_FKpny2K5"
      },
      "source": [
        "### Tuning hyperparameters with a grid search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQIZhaPqzAdw"
      },
      "source": [
        "# initialize model and define the space of the hyperparameters to\n",
        "# perform the grid-search over\n",
        "model = SVR()\n",
        "kernel = [\"linear\", \"rbf\", \"sigmoid\", \"poly\"]\n",
        "tolerance = [1e-3, 1e-4, 1e-5, 1e-6]\n",
        "C = [1, 1.5, 2, 2.5, 3]\n",
        "grid = dict(kernel=kernel, tol=tolerance, C=C)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndsNhKJNzFY2"
      },
      "source": [
        "# initialize a cross-validation fold and perform a grid-search to\n",
        "# tune the hyperparameters\n",
        "print(\"[INFO] grid searching over the hyperparameters...\")\n",
        "cvFold = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "gridSearch = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1,\n",
        "\tcv=cvFold, scoring=\"neg_mean_squared_error\")\n",
        "searchResults = gridSearch.fit(trainX, trainY)\n",
        "\n",
        "# extract the best model and evaluate it\n",
        "print(\"[INFO] evaluating...\")\n",
        "bestModel = searchResults.best_estimator_\n",
        "print(\"R2: {:.2f}\".format(bestModel.score(testX, testY)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtW_vOJSzT9q"
      },
      "source": [
        "### Tuning hyperparameters with a randomized search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXWuoTOIzJdF"
      },
      "source": [
        "# initialize model and define the space of the hyperparameters to\n",
        "# perform the randomized-search over\n",
        "model = SVR()\n",
        "kernel = [\"linear\", \"rbf\", \"sigmoid\", \"poly\"]\n",
        "tolerance = loguniform(1e-6, 1e-3)\n",
        "C = [1, 1.5, 2, 2.5, 3]\n",
        "grid = dict(kernel=kernel, tol=tolerance, C=C)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6LLKp0ZzvEV"
      },
      "source": [
        "# initialize a cross-validation fold and perform a randomized-search \n",
        "# to tune the hyperparameters\n",
        "print(\"[INFO] grid searching over the hyperparameters...\")\n",
        "cvFold = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "randomSearch = RandomizedSearchCV(estimator=model, n_jobs=-1,\n",
        "\tcv=cvFold, param_distributions=grid,\n",
        "\tscoring=\"neg_mean_squared_error\")\n",
        "searchResults = randomSearch.fit(trainX, trainY)\n",
        "\n",
        "# extract the best model and evaluate it\n",
        "print(\"[INFO] evaluating...\")\n",
        "bestModel = searchResults.best_estimator_\n",
        "print(\"R2: {:.2f}\".format(bestModel.score(testX, testY)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ogkNauArL6u"
      },
      "source": [
        "For a detailed walkthrough of the concepts and code, be sure to refer to the full tutorial, [*Introduction to hyperparameter tuning with scikit-learn and Python*](https://www.pyimagesearch.com/2021/05/17/introduction-to-hyperparameter-tuning-with-scikit-learn-and-python/) published on 2021-05-17."
      ]
    }
  ]
}