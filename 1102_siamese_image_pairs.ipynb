{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1102-siamese_image_pairs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parekhakhil/pyImageSearch/blob/main/1102_siamese_image_pairs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3HxshYShGnN"
      },
      "source": [
        "# Building image pairs for siamese networks with Python\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE4PGr_IhOXp"
      },
      "source": [
        "\n",
        "This notebook is associated with the [Building image pairs for siamese networks with Python](https://www.pyimagesearch.com/2020/11/23/building-image-pairs-for-siamese-networks-with-python/) blog post published on 11-23-20.\n",
        "\n",
        "Only the code for the blog post is here. Most codeblocks have a 1:1 relationship with what you find in the blog post with two exceptions: (1) Python classes are not separate files as they are typically organized with PyImageSearch projects, and (2) Command Line Argument parsing is replaced with an `args` dictionary that you can manipulate as needed.\n",
        "\n",
        "We recommend that you execute (press ▶️) the code block-by-block, as-is, before adjusting parameters and `args` inputs. Once you've verified that the code is working, you are welcome to hack with it and learn from manipulating inputs, settings, and parameters. For more information on using Jupyter and Colab, please refer to these resources:\n",
        "\n",
        "*   [Jupyter Notebook User Interface](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html#notebook-user-interface)\n",
        "*   [Overview of Google Colaboratory Features](https://colab.research.google.com/notebooks/basic_features_overview.ipynb)\n",
        "\n",
        "\n",
        "Happy hacking!\n",
        "\n",
        "\n",
        "\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hx5R09V1hbQM"
      },
      "source": [
        "### Download the code zip file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rU24Rwag5sF"
      },
      "source": [
        "!wget https://pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com/siamese-image-pairs/siamese-image-pairs.zip\n",
        "!unzip -qq siamese-image-pairs.zip\n",
        "%cd siamese-image-pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DST7MDR0hnuw"
      },
      "source": [
        "## Blog Post Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e1MhjRuhtUr"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y329lP2JhlYr"
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from imutils import build_montages\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmmM5W0_iJMR"
      },
      "source": [
        "### Function to display images in Jupyter Notebooks and Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hp4BbXriLDu"
      },
      "source": [
        "def plt_imshow(title, image):\n",
        "\t# convert the image frame BGR to RGB color space and display it\n",
        "\tplt.figure(figsize=(12, 12))\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\tplt.imshow(image)\n",
        "\tplt.title(title)\n",
        "\tplt.grid(False)\n",
        "\tplt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fkE1a2OpaDH"
      },
      "source": [
        "### Implementing our image pair generator for siamese networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEZlRWxzh5_R"
      },
      "source": [
        "def make_pairs(images, labels):\n",
        "\t# initialize two empty lists to hold the (image, image) pairs and\n",
        "\t# labels to indicate if a pair is positive or negative\n",
        "\tpairImages = []\n",
        "\tpairLabels = []\n",
        "\n",
        "\t# calculate the total number of classes present in the dataset\n",
        "\t# and then build a list of indexes for each class label that\n",
        "\t# provides the indexes for all examples with a given label\n",
        "\tnumClasses = len(np.unique(labels))\n",
        "\tidx = [np.where(labels == i)[0] for i in range(0, numClasses)]\n",
        "\n",
        "\t# loop over all images\n",
        "\tfor idxA in range(len(images)):\n",
        "\t\t# grab the current image and label belonging to the current\n",
        "\t\t# iteration\n",
        "\t\tcurrentImage = images[idxA]\n",
        "\t\tlabel = labels[idxA]\n",
        "\n",
        "\t\t# randomly pick an image that belongs to the *same* class\n",
        "\t\t# label\n",
        "\t\tidxB = np.random.choice(idx[label])\n",
        "\t\tposImage = images[idxB]\n",
        "\n",
        "\t\t# prepare a positive pair and update the images and labels\n",
        "\t\t# lists, respectively\n",
        "\t\tpairImages.append([currentImage, posImage])\n",
        "\t\tpairLabels.append([1])\n",
        "\n",
        "\t\t# grab the indices for each of the class labels *not* equal to\n",
        "\t\t# the current label and randomly pick an image corresponding\n",
        "\t\t# to a label *not* equal to the current label\n",
        "\t\tnegIdx = np.where(labels != label)[0]\n",
        "\t\tnegImage = images[np.random.choice(negIdx)]\n",
        "\n",
        "\t\t# prepare a negative pair of images and update our lists\n",
        "\t\tpairImages.append([currentImage, negImage])\n",
        "\t\tpairLabels.append([0])\n",
        "\n",
        "\t# return a 2-tuple of our image pairs and labels\n",
        "\treturn (np.array(pairImages), np.array(pairLabels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2QjVomHiGdz"
      },
      "source": [
        "# load MNIST dataset and scale the pixel values to the range of [0, 1]\n",
        "print(\"[INFO] loading MNIST dataset...\")\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "\n",
        "# build the positive and negative image pairs\n",
        "print(\"[INFO] preparing positive and negative pairs...\")\n",
        "(pairTrain, labelTrain) = make_pairs(trainX, trainY)\n",
        "(pairTest, labelTest) = make_pairs(testX, testY)\n",
        "\n",
        "# initialize the list of images that will be used when building our\n",
        "# montage\n",
        "images = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_gqOSZOiShE"
      },
      "source": [
        "# loop over a sample of our training pairs\n",
        "for i in np.random.choice(np.arange(0, len(pairTrain)), size=(49,)):\n",
        "\t# grab the current image pair and label\n",
        "\timageA = pairTrain[i][0]\n",
        "\timageB = pairTrain[i][1]\n",
        "\tlabel = labelTrain[i]\n",
        "\n",
        "\t# to make it easier to visualize the pairs and their positive or\n",
        "\t# negative annotations, we're going to \"pad\" the pair with four\n",
        "\t# pixels along the top, bottom, and right borders, respectively\n",
        "\toutput = np.zeros((36, 60), dtype=\"uint8\")\n",
        "\tpair = np.hstack([imageA, imageB])\n",
        "\toutput[4:32, 0:56] = pair\n",
        "\n",
        "\t# set the text label for the pair along with what color we are\n",
        "\t# going to draw the pair in (green for a \"positive\" pair and\n",
        "\t# red for a \"negative\" pair)\n",
        "\ttext = \"neg\" if label[0] == 0 else \"pos\"\n",
        "\tcolor = (0, 0, 255) if label[0] == 0 else (0, 255, 0)\n",
        "\n",
        "\t# create a 3-channel RGB image from the grayscale pair, resize\n",
        "\t# it from 28x28 to 96x51 (so we can better see it), and then\n",
        "\t# draw what type of pair it is on the image\n",
        "\tvis = cv2.merge([output] * 3)\n",
        "\tvis = cv2.resize(vis, (96, 51), interpolation=cv2.INTER_LINEAR)\n",
        "\tcv2.putText(vis, text, (2, 12), cv2.FONT_HERSHEY_SIMPLEX, 0.75,\n",
        "\t\tcolor, 2)\n",
        "\n",
        "\t# add the pair visualization to our list of output images\n",
        "\timages.append(vis)\n",
        "\n",
        "# construct the montage for the images\n",
        "montage = build_montages(images, (96, 51), (7, 7))[0]\n",
        "\n",
        "# show the output montage\n",
        "plt_imshow(\"Siamese Image Pairs\", montage)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-cKUZwKi28k"
      },
      "source": [
        "For a detailed walkthrough of the concepts and code, be sure to refer to the full tutorial, [*Building image pairs for siamese networks with Python*](https://www.pyimagesearch.com/2020/11/23/building-image-pairs-for-siamese-networks-with-python/) blog post published on 11-23-20."
      ]
    }
  ]
}