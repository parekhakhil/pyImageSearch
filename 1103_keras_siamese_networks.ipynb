{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1103-keras_siamese_networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parekhakhil/pyImageSearch/blob/main/1103_keras_siamese_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqNl6ZBb8MJ2"
      },
      "source": [
        "# Siamese networks with Keras, TensorFlow, and Deep Learning\n",
        "\n",
        "### by [PyImageSearch.com](http://www.pyimagesearch.com)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMOTEi8h8T7h"
      },
      "source": [
        "\n",
        "This notebook is associated with the [Siamese networks with Keras, TensorFlow, and Deep Learning](https://www.pyimagesearch.com/2020/11/30/siamese-networks-with-keras-tensorflow-and-deep-learning/) blog post published on 11-30-20.\n",
        "\n",
        "Only the code for the blog post is here. Most codeblocks have a 1:1 relationship with what you find in the blog post with two exceptions: (1) Python classes are not separate files as they are typically organized with PyImageSearch projects, and (2) Command Line Argument parsing is replaced with an `args` dictionary that you can manipulate as needed.\n",
        "\n",
        "We recommend that you execute (press ▶️) the code block-by-block, as-is, before adjusting parameters and `args` inputs. Once you've verified that the code is working, you are welcome to hack with it and learn from manipulating inputs, settings, and parameters. For more information on using Jupyter and Colab, please refer to these resources:\n",
        "\n",
        "*   [Jupyter Notebook User Interface](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html#notebook-user-interface)\n",
        "*   [Overview of Google Colaboratory Features](https://colab.research.google.com/notebooks/basic_features_overview.ipynb)\n",
        "\n",
        "\n",
        "\n",
        "Happy hacking!\n",
        "\n",
        "\n",
        "\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpuM4JQK-ecz"
      },
      "source": [
        "### Install the necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdtSckfk-hua"
      },
      "source": [
        "!pip install tensorflow==2.3.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM0TNh1V8gtB"
      },
      "source": [
        "### Download the code zip file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAdx4mZs78xy"
      },
      "source": [
        "!wget https://pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com/keras-siamese-networks/keras-siamese-networks.zip\n",
        "!unzip -qq keras-siamese-networks.zip\n",
        "%cd keras-siamese-networks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s4k9ZhY8wd5"
      },
      "source": [
        "## Blog Post Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tvqfs0Z38xtq"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heyL2WI580Xn"
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import tensorflow.keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYdF2X0ADkQS"
      },
      "source": [
        "### Define our `Config` class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_G1E-vBDj0A"
      },
      "source": [
        "class Config:\n",
        "    # specify the shape of the inputs for our network\n",
        "    IMG_SHAPE = (28, 28, 1)\n",
        "    \n",
        "    # specify the batch size and number of epochs\n",
        "    BATCH_SIZE = 64\n",
        "    EPOCHS = 100\n",
        "\n",
        "    # define the path to the base output directory\n",
        "    BASE_OUTPUT = \"output\"\n",
        "\n",
        "    # use the base output path to derive the path to the serialized\n",
        "    # model along with training history plot\n",
        "    MODEL_PATH = os.path.sep.join([BASE_OUTPUT, \"siamese_model\"])\n",
        "    PLOT_PATH = os.path.sep.join([BASE_OUTPUT, \"plot.png\"])\n",
        "\n",
        "# instantiate the config class\n",
        "config = Config()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGPJ8m4lEn74"
      },
      "source": [
        "### Implementing our pair generation, euclidean distance, and plot history utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3ZSyp6YEtJx"
      },
      "source": [
        "def make_pairs(images, labels):\n",
        "\t# initialize two empty lists to hold the (image, image) pairs and\n",
        "\t# labels to indicate if a pair is positive or negative\n",
        "\tpairImages = []\n",
        "\tpairLabels = []\n",
        "\n",
        "\t# calculate the total number of classes present in the dataset\n",
        "\t# and then build a list of indexes for each class label that\n",
        "\t# provides the indexes for all examples with a given label\n",
        "\tnumClasses = len(np.unique(labels))\n",
        "\tidx = [np.where(labels == i)[0] for i in range(0, numClasses)]\n",
        "\n",
        "\t# loop over all images\n",
        "\tfor idxA in range(len(images)):\n",
        "\t\t# grab the current image and label belonging to the current\n",
        "\t\t# iteration\n",
        "\t\tcurrentImage = images[idxA]\n",
        "\t\tlabel = labels[idxA]\n",
        "\n",
        "\t\t# randomly pick an image that belongs to the *same* class\n",
        "\t\t# label\n",
        "\t\tidxB = np.random.choice(idx[label])\n",
        "\t\tposImage = images[idxB]\n",
        "\n",
        "\t\t# prepare a positive pair and update the images and labels\n",
        "\t\t# lists, respectively\n",
        "\t\tpairImages.append([currentImage, posImage])\n",
        "\t\tpairLabels.append([1])\n",
        "\n",
        "\t\t# grab the indices for each of the class labels *not* equal to\n",
        "\t\t# the current label and randomly pick an image corresponding\n",
        "\t\t# to a label *not* equal to the current label\n",
        "\t\tnegIdx = np.where(labels != label)[0]\n",
        "\t\tnegImage = images[np.random.choice(negIdx)]\n",
        "\n",
        "\t\t# prepare a negative pair of images and update our lists\n",
        "\t\tpairImages.append([currentImage, negImage])\n",
        "\t\tpairLabels.append([0])\n",
        "\n",
        "\t# return a 2-tuple of our image pairs and labels\n",
        "\treturn (np.array(pairImages), np.array(pairLabels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXcPVZCGE1ly"
      },
      "source": [
        "def euclidean_distance(vectors):\n",
        "\t# unpack the vectors into separate lists\n",
        "\t(featsA, featsB) = vectors\n",
        "\n",
        "\t# compute the sum of squared distances between the vectors\n",
        "\tsumSquared = K.sum(K.square(featsA - featsB), axis=1,\n",
        "\t\tkeepdims=True)\n",
        "\n",
        "\t# return the euclidean distance between the vectors\n",
        "\treturn K.sqrt(K.maximum(sumSquared, K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3QoY24wE7NK"
      },
      "source": [
        "def plot_training(H, plotPath):\n",
        "\t# construct a plot that plots and saves the training history\n",
        "\tplt.style.use(\"ggplot\")\n",
        "\tplt.figure()\n",
        "\tplt.plot(H.history[\"loss\"], label=\"train_loss\")\n",
        "\tplt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n",
        "\tplt.plot(H.history[\"accuracy\"], label=\"train_acc\")\n",
        "\tplt.plot(H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "\tplt.title(\"Training Loss and Accuracy\")\n",
        "\tplt.xlabel(\"Epoch #\")\n",
        "\tplt.ylabel(\"Loss/Accuracy\")\n",
        "\tplt.legend(loc=\"lower left\")\n",
        "\tplt.savefig(plotPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8yghffrFB4a"
      },
      "source": [
        "### Implementing the siamese network architecture with Keras and TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B67R684AFHs0"
      },
      "source": [
        "def build_siamese_model(inputShape, embeddingDim=48):\n",
        "\t# specify the inputs for the feature extractor network\n",
        "\tinputs = Input(inputShape)\n",
        "\n",
        "\t# define the first set of CONV => RELU => POOL => DROPOUT layers\n",
        "\tx = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(inputs)\n",
        "\tx = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\tx = Dropout(0.3)(x)\n",
        "\n",
        "\t# second set of CONV => RELU => POOL => DROPOUT layers\n",
        "\tx = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(x)\n",
        "\tx = MaxPooling2D(pool_size=2)(x)\n",
        "\tx = Dropout(0.3)(x)\n",
        "\n",
        "\t# prepare the final outputs\n",
        "\tpooledOutput = GlobalAveragePooling2D()(x)\n",
        "\toutputs = Dense(embeddingDim)(pooledOutput)\n",
        "\n",
        "\t# build the model\n",
        "\tmodel = Model(inputs, outputs)\n",
        "\n",
        "\t# return the model to the calling function\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRQ4Nj14FT3j"
      },
      "source": [
        "### Training our siamese network with Keras and TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BynHE9sRFgod"
      },
      "source": [
        "# load MNIST dataset and scale the pixel values to the range of [0, 1]\n",
        "print(\"[INFO] loading MNIST dataset...\")\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "trainX = trainX / 255.0\n",
        "testX = testX / 255.0\n",
        "\n",
        "# add a channel dimension to the images\n",
        "trainX = np.expand_dims(trainX, axis=-1)\n",
        "testX = np.expand_dims(testX, axis=-1)\n",
        "\n",
        "# prepare the positive and negative pairs\n",
        "print(\"[INFO] preparing positive and negative pairs...\")\n",
        "(pairTrain, labelTrain) = make_pairs(trainX, trainY)\n",
        "(pairTest, labelTest) = make_pairs(testX, testY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj_BrKi-FljA"
      },
      "source": [
        "# configure the siamese network\n",
        "print(\"[INFO] building siamese network...\")\n",
        "imgA = Input(shape=config.IMG_SHAPE)\n",
        "imgB = Input(shape=config.IMG_SHAPE)\n",
        "featureExtractor = build_siamese_model(config.IMG_SHAPE)\n",
        "featsA = featureExtractor(imgA)\n",
        "featsB = featureExtractor(imgB)\n",
        "\n",
        "# finally, construct the siamese network\n",
        "distance = Lambda(euclidean_distance)([featsA, featsB])\n",
        "outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
        "model = Model(inputs=[imgA, imgB], outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev4OcOf7FwV5"
      },
      "source": [
        "# compile the model\n",
        "print(\"[INFO] compiling model...\")\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "# train the model\n",
        "print(\"[INFO] training model...\")\n",
        "history = model.fit(\n",
        "\t[pairTrain[:, 0], pairTrain[:, 1]], labelTrain[:],\n",
        "\tvalidation_data=([pairTest[:, 0], pairTest[:, 1]], labelTest[:]),\n",
        "\tbatch_size=config.BATCH_SIZE, \n",
        "\tepochs=config.EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9FVEsjaF_QH"
      },
      "source": [
        "# serialize the model to disk\n",
        "print(\"[INFO] saving siamese model...\")\n",
        "model.save(config.MODEL_PATH)\n",
        "\n",
        "# plot the training history\n",
        "print(\"[INFO] plotting training history...\")\n",
        "plot_training(history, config.PLOT_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXqcN65kGVpe"
      },
      "source": [
        "For a detailed walkthrough of the concepts and code, be sure to refer to the full tutorial, [*Siamese networks with Keras, TensorFlow, and Deep Learning*](https://www.pyimagesearch.com/2020/11/30/siamese-networks-with-keras-tensorflow-and-deep-learning/) blog post published on 11-30-20."
      ]
    }
  ]
}