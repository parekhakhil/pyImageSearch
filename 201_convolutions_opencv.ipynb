{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "201-convolutions_opencv.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parekhakhil/pyImageSearch/blob/main/201_convolutions_opencv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4RpK9pawQzP"
      },
      "source": [
        "# Convolutions with OpenCV and Python\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ntZ1AkXZIxY"
      },
      "source": [
        "## Welcome to **[PyImageSearch Plus](http://pyimg.co/plus)** Jupyter Notebooks!\n",
        "\n",
        "This notebook is associated with the [Convolutions with OpenCV and Python](https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/) blog post published on 2016-07-25.\n",
        "\n",
        "Only the code for the blog post is here. Most codeblocks have a 1:1 relationship with what you find in the blog post with two exceptions: (1) Python classes are not separate files as they are typically organized with PyImageSearch projects, and (2) Command Line Argument parsing is replaced with an `args` dictionary that you can manipulate as needed.\n",
        "\n",
        "We recommend that you execute (press ▶️) the code block-by-block, as-is, before adjusting parameters and `args` inputs. Once you've verified that the code is working, you are welcome to hack with it and learn from manipulating inputs, settings, and parameters. For more information on using Jupyter and Colab, please refer to these resources:\n",
        "\n",
        "*   [Jupyter Notebook User Interface](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html#notebook-user-interface)\n",
        "*   [Overview of Google Colaboratory Features](https://colab.research.google.com/notebooks/basic_features_overview.ipynb)\n",
        "\n",
        "\n",
        "Happy hacking!\n",
        "\n",
        "\n",
        "\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFhAzQB3aNMa"
      },
      "source": [
        "### Download the code zip file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y0LG1EuaRlB"
      },
      "source": [
        "!wget https://www.pyimagesearch.com/wp-content/uploads/2016/06/convolutions-opencv.zip\n",
        "!unzip -qq convolutions-opencv.zip\n",
        "%cd convolutions-opencv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SgTVT3HagGZ"
      },
      "source": [
        "## Blog Post Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcrOk6pURp50"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJaCNlDDRz6d"
      },
      "source": [
        "# import the necessary packages\n",
        "from skimage.exposure import rescale_intensity\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBrLwCtN5kqy"
      },
      "source": [
        "### Function to display images in Jupyter Notebooks and Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRw969Dp5Kdm"
      },
      "source": [
        "def plt_imshow(title, image):\n",
        "\t# convert the image frame BGR to RGB color space and display it\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\tplt.imshow(image)\n",
        "\tplt.title(title)\n",
        "\tplt.grid(False)\n",
        "\tplt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jppw5-Bd56H-"
      },
      "source": [
        "### Heading of the section covering script Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "intTGX9ZldSA"
      },
      "source": [
        "def convolve(image, kernel):\n",
        "\t# grab the spatial dimensions of the image, along with\n",
        "\t# the spatial dimensions of the kernel\n",
        "\t(iH, iW) = image.shape[:2]\n",
        "\t(kH, kW) = kernel.shape[:2]\n",
        "\n",
        "\t# allocate memory for the output image, taking care to\n",
        "\t# \"pad\" the borders of the input image so the spatial\n",
        "\t# size (i.e., width and height) are not reduced\n",
        "\tpad = (kW - 1) // 2\n",
        "\timage = cv2.copyMakeBorder(image, pad, pad, pad, pad,\n",
        "\t\tcv2.BORDER_REPLICATE)\n",
        "\toutput = np.zeros((iH, iW), dtype=\"float32\")\n",
        "\n",
        "\t# loop over the input image, \"sliding\" the kernel across\n",
        "\t# each (x, y)-coordinate from left-to-right and top to\n",
        "\t# bottom\n",
        "\tfor y in np.arange(pad, iH + pad):\n",
        "\t\tfor x in np.arange(pad, iW + pad):\n",
        "\t\t\t# extract the ROI of the image by extracting the\n",
        "\t\t\t# *center* region of the current (x, y)-coordinates\n",
        "\t\t\t# dimensions\n",
        "\t\t\troi = image[y - pad:y + pad + 1, x - pad:x + pad + 1]\n",
        "\n",
        "\t\t\t# perform the actual convolution by taking the\n",
        "\t\t\t# element-wise multiplicate between the ROI and\n",
        "\t\t\t# the kernel, then summing the matrix\n",
        "\t\t\tk = (roi * kernel).sum()\n",
        "\n",
        "\t\t\t# store the convolved value in the output (x,y)-\n",
        "\t\t\t# coordinate of the output image\n",
        "\t\t\toutput[y - pad, x - pad] = k\n",
        "\n",
        "\t# rescale the output image to be in the range [0, 255]\n",
        "\toutput = rescale_intensity(output, in_range=(0, 255))\n",
        "\toutput = (output * 255).astype(\"uint8\")\n",
        "\n",
        "\t# return the output image\n",
        "\treturn output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okM7Bpyeq8Kc"
      },
      "source": [
        "# construct the argument parser and parse the arguments\n",
        "# ap = argparse.ArgumentParser()\n",
        "# ap.add_argument(\"-i\", \"--image\", required=True,\n",
        "# \thelp=\"path to the input image\")\n",
        "# args = vars(ap.parse_args())\n",
        "\n",
        "# since we are using Jupyter Notebooks we can replace our argument\n",
        "# parsing code with *hard coded* arguments and values\n",
        "args = {\n",
        "\t\"image\": \"3d_pokemon.png\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAIvrpXslpWi"
      },
      "source": [
        "# construct average blurring kernels used to smooth an image\n",
        "smallBlur = np.ones((7, 7), dtype=\"float\") * (1.0 / (7 * 7))\n",
        "largeBlur = np.ones((21, 21), dtype=\"float\") * (1.0 / (21 * 21))\n",
        "\n",
        "# construct a sharpening filter\n",
        "sharpen = np.array((\n",
        "\t[0, -1, 0],\n",
        "\t[-1, 5, -1],\n",
        "\t[0, -1, 0]), dtype=\"int\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvLXZuhPlpTa"
      },
      "source": [
        "# construct the Laplacian kernel used to detect edge-like\n",
        "# regions of an image\n",
        "laplacian = np.array((\n",
        "\t[0, 1, 0],\n",
        "\t[1, -4, 1],\n",
        "\t[0, 1, 0]), dtype=\"int\")\n",
        "\n",
        "# construct the Sobel x-axis kernel\n",
        "sobelX = np.array((\n",
        "\t[-1, 0, 1],\n",
        "\t[-2, 0, 2],\n",
        "\t[-1, 0, 1]), dtype=\"int\")\n",
        "\n",
        "# construct the Sobel y-axis kernel\n",
        "sobelY = np.array((\n",
        "\t[-1, -2, -1],\n",
        "\t[0, 0, 0],\n",
        "\t[1, 2, 1]), dtype=\"int\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi71H-tAl4nx"
      },
      "source": [
        "# construct the kernel bank, a list of kernels we're going\n",
        "# to apply using both our custom `convole` function and\n",
        "# OpenCV's `filter2D` function\n",
        "kernelBank = (\n",
        "\t(\"small_blur\", smallBlur),\n",
        "\t(\"large_blur\", largeBlur),\n",
        "\t(\"sharpen\", sharpen),\n",
        "\t(\"laplacian\", laplacian),\n",
        "\t(\"sobel_x\", sobelX),\n",
        "\t(\"sobel_y\", sobelY)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HToQ85rKl4lr"
      },
      "source": [
        "# load the input image and convert it to grayscale\n",
        "image = cv2.imread(args[\"image\"])\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# loop over the kernels\n",
        "for (kernelName, kernel) in kernelBank:\n",
        "\t# apply the kernel to the grayscale image using both\n",
        "\t# our custom `convole` function and OpenCV's `filter2D`\n",
        "\t# function\n",
        "\tprint(\"[INFO] applying {} kernel\".format(kernelName))\n",
        "\tconvoleOutput = convolve(gray, kernel)\n",
        "\topencvOutput = cv2.filter2D(gray, -1, kernel)\n",
        "\n",
        "\t# show the output images\n",
        "\tplt_imshow(\"original\", gray)\n",
        "\tplt_imshow(\"{} - convole\".format(kernelName), convoleOutput)\n",
        "\tplt_imshow(\"{} - opencv\".format(kernelName), opencvOutput)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ogkNauArL6u"
      },
      "source": [
        "For a detailed walkthrough of the concepts and code, be sure to refer to the full tutorial, [*Convolutions with OpenCV and Python*](https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/) published on 2016-07-25."
      ]
    }
  ]
}