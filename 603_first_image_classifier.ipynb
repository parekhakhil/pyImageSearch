{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "603-first_image_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parekhakhil/pyImageSearch/blob/main/603_first_image_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4RpK9pawQzP"
      },
      "source": [
        "# Your First Image Classifier: Using k-NN to Classify Images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ntZ1AkXZIxY"
      },
      "source": [
        "\n",
        "\n",
        "This notebook is associated with the [Your First Image Classifier: Using k-NN to Classify Images](https://www.pyimagesearch.com/2021/04/17/your-first-image-classifier-using-k-nn-to-classify-images/) blog post published on 2021-04-17.\n",
        "\n",
        "Only the code for the blog post is here. Most codeblocks have a 1:1 relationship with what you find in the blog post with two exceptions: (1) Python classes are not separate files as they are typically organized with PyImageSearch projects, and (2) Command Line Argument parsing is replaced with an `args` dictionary that you can manipulate as needed.\n",
        "\n",
        "We recommend that you execute (press ▶️) the code block-by-block, as-is, before adjusting parameters and `args` inputs. Once you've verified that the code is working, you are welcome to hack with it and learn from manipulating inputs, settings, and parameters. For more information on using Jupyter and Colab, please refer to these resources:\n",
        "\n",
        "*   [Jupyter Notebook User Interface](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html#notebook-user-interface)\n",
        "*   [Overview of Google Colaboratory Features](https://colab.research.google.com/notebooks/basic_features_overview.ipynb)\n",
        "\n",
        "\n",
        "\n",
        "Happy hacking!\n",
        "\n",
        "\n",
        "\n",
        "<hr>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFhAzQB3aNMa"
      },
      "source": [
        "### Download the code zip file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y0LG1EuaRlB"
      },
      "source": [
        "!wget https://pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com/first-image-classifier/first-image-classifier.zip\n",
        "!unzip -qq first-image-classifier.zip\n",
        "%cd first-image-classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SgTVT3HagGZ"
      },
      "source": [
        "## Blog Post Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcrOk6pURp50"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJaCNlDDRz6d"
      },
      "source": [
        "# import the necessary packages\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbdZmfJJONLt"
      },
      "source": [
        "### A Basic Image Preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYl4nfHpOO0o"
      },
      "source": [
        "class SimplePreprocessor:\n",
        "\tdef __init__(self, width, height, inter=cv2.INTER_AREA):\n",
        "\t\t# store the target image width, height, and interpolation\n",
        "\t\t# method used when resizing\n",
        "\t\tself.width = width\n",
        "\t\tself.height = height\n",
        "\t\tself.inter = inter\n",
        "\n",
        "\tdef preprocess(self, image):\n",
        "\t\t# resize the image to a fixed size, ignoring the aspect\n",
        "\t\t# ratio\n",
        "\t\treturn cv2.resize(image, (self.width, self.height),\n",
        "\t\t\tinterpolation=self.inter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPZw12wrOUO7"
      },
      "source": [
        "### Building an Image Loader "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcE_moyMOVMy"
      },
      "source": [
        "class SimpleDatasetLoader:\n",
        "\tdef __init__(self, preprocessors=None):\n",
        "\t\t# store the image preprocessor\n",
        "\t\tself.preprocessors = preprocessors\n",
        "\n",
        "\t\t# if the preprocessors are None, initialize them as an\n",
        "\t\t# empty list\n",
        "\t\tif self.preprocessors is None:\n",
        "\t\t\tself.preprocessors = []\n",
        "\n",
        "\tdef load(self, imagePaths, verbose=-1):\n",
        "\t\t# initialize the list of features and labels\n",
        "\t\tdata = []\n",
        "\t\tlabels = []\n",
        "\n",
        "\t\t# loop over the input images\n",
        "\t\tfor (i, imagePath) in enumerate(imagePaths):\n",
        "\t\t\t# load the image and extract the class label assuming\n",
        "\t\t\t# that our path has the following format:\n",
        "\t\t\t# /path/to/dataset/{class}/{image}.jpg\n",
        "\t\t\timage = cv2.imread(imagePath)\n",
        "\t\t\tlabel = imagePath.split(os.path.sep)[-2]\n",
        "\n",
        "            # check to see if our preprocessors are not None\n",
        "\t\t\tif self.preprocessors is not None:\n",
        "\t\t\t\t# loop over the preprocessors and apply each to\n",
        "\t\t\t\t# the image\n",
        "\t\t\t\tfor p in self.preprocessors:\n",
        "\t\t\t\t\timage = p.preprocess(image)\n",
        "\n",
        "\t\t\t# treat our processed image as a \"feature vector\"\n",
        "\t\t\t# by updating the data list followed by the labels\n",
        "\t\t\tdata.append(image)\n",
        "\t\t\tlabels.append(label)\n",
        "   \n",
        "\t\t\t# show an update every `verbose` images\n",
        "\t\t\tif verbose > 0 and i > 0 and (i + 1) % verbose == 0:\n",
        "\t\t\t\tprint(\"[INFO] processed {}/{}\".format(i + 1,\n",
        "\t\t\t\t\tlen(imagePaths)))\n",
        "\n",
        "\t\t# return a tuple of the data and labels\n",
        "\t\treturn (np.array(data), np.array(labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jppw5-Bd56H-"
      },
      "source": [
        "### Implementing k-NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okM7Bpyeq8Kc"
      },
      "source": [
        "# construct the argument parse and parse the arguments\n",
        "#ap = argparse.ArgumentParser()\n",
        "#ap.add_argument(\"-d\", \"--dataset\", required=True,\n",
        "#\thelp=\"path to input dataset\")\n",
        "#ap.add_argument(\"-k\", \"--neighbors\", type=int, default=1,\n",
        "#\thelp=\"# of nearest neighbors for classification\")\n",
        "#ap.add_argument(\"-j\", \"--jobs\", type=int, default=-1,\n",
        "#\thelp=\"# of jobs for k-NN distance (-1 uses all available cores)\")\n",
        "#args = vars(ap.parse_args())\n",
        "\n",
        "# since we are using Jupyter Notebooks we can replace our argument\n",
        "# parsing code with *hard coded* arguments and values\n",
        "args = {\n",
        "\t\"dataset\": \"dataset/animals\",\n",
        "\t\"neighbors\": 1,\n",
        "\t\"jobs\": -1\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPNlfJqmcoyo"
      },
      "source": [
        "# grab the list of images that we'll be describing\n",
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = list(paths.list_images(args[\"dataset\"]))\n",
        "\n",
        "# initialize the image preprocessor, load the dataset from disk,\n",
        "# and reshape the data matrix\n",
        "sp = SimplePreprocessor(32, 32)\n",
        "sdl = SimpleDatasetLoader(preprocessors=[sp])\n",
        "(data, labels) = sdl.load(imagePaths, verbose=500)\n",
        "data = data.reshape((data.shape[0], 3072))\n",
        "\n",
        "# show some information on memory consumption of the images\n",
        "print(\"[INFO] features matrix: {:.1f}MB\".format(\n",
        "\tdata.nbytes / (1024 * 1024.0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX5zaVUocplp"
      },
      "source": [
        "# encode the labels as integers\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels)\n",
        "\n",
        "# partition the data into training and testing splits using 75% of\n",
        "# the data for training and the remaining 25% for testing\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
        "\ttest_size=0.25, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22kJ7cZlcsG2"
      },
      "source": [
        "# train and evaluate a k-NN classifier on the raw pixel intensities\n",
        "print(\"[INFO] evaluating k-NN classifier...\")\n",
        "model = KNeighborsClassifier(n_neighbors=args[\"neighbors\"],\n",
        "\tn_jobs=args[\"jobs\"])\n",
        "model.fit(trainX, trainY)\n",
        "print(classification_report(testY, model.predict(testX),\n",
        "\ttarget_names=le.classes_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ogkNauArL6u"
      },
      "source": [
        "For a detailed walkthrough of the concepts and code, be sure to refer to the full tutorial, [*Your First Image Classifier: Using k-NN to Classify Images*](https://www.pyimagesearch.com/2021/04/17/your-first-image-classifier-using-k-nn-to-classify-images/) published on 2021-04-17."
      ]
    }
  ]
}