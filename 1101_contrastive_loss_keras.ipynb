{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1101-contrastive_loss_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parekhakhil/pyImageSearch/blob/main/1101_contrastive_loss_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSIAjNLqI5LI"
      },
      "source": [
        "# Contrastive Loss for Siamese Networks with Keras and TensorFlow\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viKSbM-CJDkK"
      },
      "source": [
        "\n",
        "This notebook is associated with the [Contrastive Loss for Siamese Networks with Keras and TensorFlow](https://www.pyimagesearch.com/2021/01/18/contrastive-loss-for-siamese-networks-with-keras-and-tensorflow/) blog post published on 01-18-21.\n",
        "\n",
        "Only the code for the blog post is here. Most codeblocks have a 1:1 relationship with what you find in the blog post with two exceptions: (1) Python classes are not separate files as they are typically organized with PyImageSearch projects, and (2) Command Line Argument parsing is replaced with an `args` dictionary that you can manipulate as needed.\n",
        "\n",
        "We recommend that you execute (press ▶️) the code block-by-block, as-is, before adjusting parameters and `args` inputs. Once you've verified that the code is working, you are welcome to hack with it and learn from manipulating inputs, settings, and parameters. For more information on using Jupyter and Colab, please refer to these resources:\n",
        "\n",
        "*   [Jupyter Notebook User Interface](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html#notebook-user-interface)\n",
        "*   [Overview of Google Colaboratory Features](https://colab.research.google.com/notebooks/basic_features_overview.ipynb)\n",
        "\n",
        "\n",
        "\n",
        "Happy hacking!\n",
        "\n",
        "\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX9B9dPlJO9k"
      },
      "source": [
        "### Download the code zip file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwa3GuDLIZA3"
      },
      "source": [
        "!wget https://pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com/contrastive-loss-keras/contrastive-loss-keras.zip\n",
        "!unzip -qq contrastive-loss-keras.zip\n",
        "%cd contrastive-loss-keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5V8gTAZJhhn"
      },
      "source": [
        "## Blog Post Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAxelcDxJjie"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkyV3l7NJbfE"
      },
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import load_model\n",
        "from imutils.paths import list_images\n",
        "import tensorflow.keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiKV4G4oN7pU"
      },
      "source": [
        "### Our `Config` class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3AADGAoN9nm"
      },
      "source": [
        "class config:\n",
        "    # specify the shape of the inputs for our network\n",
        "    IMG_SHAPE = (28, 28, 1)\n",
        "\n",
        "    # specify the batch size and number of epochs\n",
        "    BATCH_SIZE = 64\n",
        "\n",
        "    EPOCHS = 100\n",
        "\n",
        "    # define the path to the base output directory\n",
        "    BASE_OUTPUT = \"output\"\n",
        "\n",
        "    # use the base output path to derive the path to the serialized\n",
        "    # model along with training history plot\n",
        "    MODEL_PATH = os.path.sep.join([BASE_OUTPUT,\n",
        "        \"contrastive_siamese_model\"])\n",
        "    PLOT_PATH = os.path.sep.join([BASE_OUTPUT,\n",
        "        \"contrastive_plot.png\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHHo29PxOXXX"
      },
      "source": [
        "### Creating our helper utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku0MVG5jOJ5H"
      },
      "source": [
        "def make_pairs(images, labels):\n",
        "\t# initialize two empty lists to hold the (image, image) pairs and\n",
        "\t# labels to indicate if a pair is positive or negative\n",
        "\tpairImages = []\n",
        "\tpairLabels = []\n",
        "\n",
        "\t# calculate the total number of classes present in the dataset\n",
        "\t# and then build a list of indexes for each class label that\n",
        "\t# provides the indexes for all examples with a given label\n",
        "\tnumClasses = len(np.unique(labels))\n",
        "\tidx = [np.where(labels == i)[0] for i in range(0, numClasses)]\n",
        "\n",
        "\t# loop over all images\n",
        "\tfor idxA in range(len(images)):\n",
        "\t\t# grab the current image and label belonging to the current\n",
        "\t\t# iteration\n",
        "\t\tcurrentImage = images[idxA]\n",
        "\t\tlabel = labels[idxA]\n",
        "\n",
        "\t\t# randomly pick an image that belongs to the *same* class\n",
        "\t\t# label\n",
        "\t\tidxB = np.random.choice(idx[label])\n",
        "\t\tposImage = images[idxB]\n",
        "\n",
        "\t\t# prepare a positive pair and update the images and labels\n",
        "\t\t# lists, respectively\n",
        "\t\tpairImages.append([currentImage, posImage])\n",
        "\t\tpairLabels.append([1])\n",
        "\n",
        "\t\t# grab the indices for each of the class labels *not* equal to\n",
        "\t\t# the current label and randomly pick an image corresponding\n",
        "\t\t# to a label *not* equal to the current label\n",
        "\t\tnegIdx = np.where(labels != label)[0]\n",
        "\t\tnegImage = images[np.random.choice(negIdx)]\n",
        "\n",
        "\t\t# prepare a negative pair of images and update our lists\n",
        "\t\tpairImages.append([currentImage, negImage])\n",
        "\t\tpairLabels.append([0])\n",
        "\n",
        "\t# return a 2-tuple of our image pairs and labels\n",
        "\treturn (np.array(pairImages), np.array(pairLabels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH_pZEYdOpDr"
      },
      "source": [
        "def euclidean_distance(vectors):\n",
        "\t# unpack the vectors into separate lists\n",
        "\t(featsA, featsB) = vectors\n",
        "\n",
        "\t# compute the sum of squared distances between the vectors\n",
        "\tsumSquared = K.sum(K.square(featsA - featsB), axis=1,\n",
        "\t\tkeepdims=True)\n",
        "\n",
        "\t# return the euclidean distance between the vectors\n",
        "\treturn K.sqrt(K.maximum(sumSquared, K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnPq25r4OsSF"
      },
      "source": [
        "def plot_training(H, plotPath):\n",
        "\t# construct a plot that plots and saves the training history\n",
        "\tplt.style.use(\"ggplot\")\n",
        "\tplt.figure()\n",
        "\tplt.plot(H.history[\"loss\"], label=\"train_loss\")\n",
        "\tplt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n",
        "\tplt.title(\"Training Loss\")\n",
        "\tplt.xlabel(\"Epoch #\")\n",
        "\tplt.ylabel(\"Loss\")\n",
        "\tplt.legend(loc=\"lower left\")\n",
        "\tplt.savefig(plotPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNxC3f7uOy7U"
      },
      "source": [
        "### Implementing our siamese network architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoLsUgB8Ou97"
      },
      "source": [
        "def build_siamese_model(inputShape, embeddingDim=48):\n",
        "\t# specify the inputs for the feature extractor network\n",
        "\tinputs = Input(inputShape)\n",
        "\n",
        "\t# define the first set of CONV => RELU => POOL => DROPOUT layers\n",
        "\tx = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(inputs)\n",
        "\tx = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\tx = Dropout(0.3)(x)\n",
        "\n",
        "\t# second set of CONV => RELU => POOL => DROPOUT layers\n",
        "\tx = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(x)\n",
        "\tx = MaxPooling2D(pool_size=2)(x)\n",
        "\tx = Dropout(0.3)(x)\n",
        "\n",
        "\t# prepare the final outputs\n",
        "\tpooledOutput = GlobalAveragePooling2D()(x)\n",
        "\toutputs = Dense(embeddingDim)(pooledOutput)\n",
        "\n",
        "\t# build the model\n",
        "\tmodel = Model(inputs, outputs)\n",
        "\n",
        "\t# return the model to the calling function\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR4xZ4yIPBLc"
      },
      "source": [
        "### Implementing contrastive loss with Keras and TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpnwyEG7O9rL"
      },
      "source": [
        "def contrastive_loss(y, preds, margin=1):\n",
        "\t# explicitly cast the true class label data type to the predicted\n",
        "\t# class label data type (otherwise we run the risk of having two\n",
        "\t# separate data types, causing TensorFlow to error out)\n",
        "\ty = tf.cast(y, preds.dtype)\n",
        "\n",
        "\t# calculate the contrastive loss between the true labels and\n",
        "\t# the predicted labels\n",
        "\tsquaredPreds = K.square(preds)\n",
        "\tsquaredMargin = K.square(K.maximum(margin - preds, 0))\n",
        "\tloss = K.mean(y * squaredPreds + (1 - y) * squaredMargin)\n",
        "\n",
        "\t# return the computed contrastive loss to the calling function\n",
        "\treturn loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJXznmckPO6o"
      },
      "source": [
        "### Creating our contrastive loss training script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHE95JUpPMQV"
      },
      "source": [
        "# load MNIST dataset and scale the pixel values to the range of [0, 1]\n",
        "print(\"[INFO] loading MNIST dataset...\")\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "trainX = trainX / 255.0\n",
        "testX = testX / 255.0\n",
        "\n",
        "# add a channel dimension to the images\n",
        "trainX = np.expand_dims(trainX, axis=-1)\n",
        "testX = np.expand_dims(testX, axis=-1)\n",
        "\n",
        "# prepare the positive and negative pairs\n",
        "print(\"[INFO] preparing positive and negative pairs...\")\n",
        "(pairTrain, labelTrain) = make_pairs(trainX, trainY)\n",
        "(pairTest, labelTest) = make_pairs(testX, testY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AESdW43tPc3J"
      },
      "source": [
        "# configure the siamese network\n",
        "print(\"[INFO] building siamese network...\")\n",
        "imgA = Input(shape=config.IMG_SHAPE)\n",
        "imgB = Input(shape=config.IMG_SHAPE)\n",
        "featureExtractor = build_siamese_model(config.IMG_SHAPE)\n",
        "featsA = featureExtractor(imgA)\n",
        "featsB = featureExtractor(imgB)\n",
        "\n",
        "# finally, construct the siamese network\n",
        "distance = Lambda(euclidean_distance)([featsA, featsB])\n",
        "model = Model(inputs=[imgA, imgB], outputs=distance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTHOBs1JPpF0"
      },
      "source": [
        "# compile the model\n",
        "print(\"[INFO] compiling model...\")\n",
        "model.compile(loss=contrastive_loss, optimizer=\"adam\")\n",
        "\n",
        "# train the model\n",
        "print(\"[INFO] training model...\")\n",
        "history = model.fit(\n",
        "\t[pairTrain[:, 0], pairTrain[:, 1]], labelTrain[:],\n",
        "\tvalidation_data=([pairTest[:, 0], pairTest[:, 1]], labelTest[:]),\n",
        "\tbatch_size=config.BATCH_SIZE,\n",
        "\tepochs=config.EPOCHS)\n",
        "\n",
        "# serialize the model to disk\n",
        "print(\"[INFO] saving siamese model...\")\n",
        "model.save(config.MODEL_PATH)\n",
        "\n",
        "# plot the training history\n",
        "print(\"[INFO] plotting training history...\")\n",
        "plot_training(history, config.PLOT_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZc9P9qpQJN0"
      },
      "source": [
        "### Implementing our contrastive loss test script\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcvtheutPxPD"
      },
      "source": [
        "# # construct the argument parser and parse the arguments\n",
        "# ap = argparse.ArgumentParser()\n",
        "# ap.add_argument(\"-i\", \"--input\", required=True,\n",
        "# \thelp=\"path to input directory of testing images\")\n",
        "# args = vars(ap.parse_args())\n",
        "\n",
        "# since we are using Jupyter Notebooks we can replace our argument\n",
        "# parsing code with *hard coded* arguments and values\n",
        "args = {\n",
        "    \"input\": \"examples\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc4ittsRQnoI"
      },
      "source": [
        "# grab the test dataset image paths and then randomly generate a\n",
        "# total of 10 image pairs\n",
        "print(\"[INFO] loading test dataset...\")\n",
        "testImagePaths = list(list_images(args[\"input\"]))\n",
        "np.random.seed(42)\n",
        "pairs = np.random.choice(testImagePaths, size=(10, 2))\n",
        "\n",
        "# load the model from disk\n",
        "print(\"[INFO] loading siamese model...\")\n",
        "model = load_model(config.MODEL_PATH, compile=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tUZMx1SQvaJ"
      },
      "source": [
        "# loop over all image pairs\n",
        "for (i, (pathA, pathB)) in enumerate(pairs):\n",
        "\t# load both the images and convert them to grayscale\n",
        "\timageA = cv2.imread(pathA, 0)\n",
        "\timageB = cv2.imread(pathB, 0)\n",
        "\n",
        "\t# create a copy of both the images for visualization purpose\n",
        "\torigA = imageA.copy()\n",
        "\torigB = imageB.copy()\n",
        "\n",
        "\t# add channel a dimension to both the images\n",
        "\timageA = np.expand_dims(imageA, axis=-1)\n",
        "\timageB = np.expand_dims(imageB, axis=-1)\n",
        "\n",
        "\t# add a batch dimension to both images\n",
        "\timageA = np.expand_dims(imageA, axis=0)\n",
        "\timageB = np.expand_dims(imageB, axis=0)\n",
        "\n",
        "\t# scale the pixel values to the range of [0, 1]\n",
        "\timageA = imageA / 255.0\n",
        "\timageB = imageB / 255.0\n",
        "\n",
        "\t# use our siamese model to make predictions on the image pair,\n",
        "\t# indicating whether or not the images belong to the same class\n",
        "\tpreds = model.predict([imageA, imageB])\n",
        "\tproba = preds[0][0]\n",
        "\n",
        "\t# initialize the figure\n",
        "\tfig = plt.figure(\"Pair #{}\".format(i + 1), figsize=(4, 2))\n",
        "\tplt.suptitle(\"Distance: {:.2f}\".format(proba))\n",
        "\n",
        "\t# show first image\n",
        "\tax = fig.add_subplot(1, 2, 1)\n",
        "\tplt.imshow(origA, cmap=plt.cm.gray)\n",
        "\tplt.axis(\"off\")\n",
        "\n",
        "\t# show the second image\n",
        "\tax = fig.add_subplot(1, 2, 2)\n",
        "\tplt.imshow(origB, cmap=plt.cm.gray)\n",
        "\tplt.axis(\"off\")\n",
        "\n",
        "\t# show the plot\n",
        "\tplt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q1x1gzOLEHB"
      },
      "source": [
        "For a detailed walkthrough of the concepts and code, be sure to refer to the full tutorial, [*Contrastive Loss for Siamese Networks with Keras and TensorFlow*](https://www.pyimagesearch.com/2021/01/18/contrastive-loss-for-siamese-networks-with-keras-and-tensorflow/) blog post published on 01-18-21."
      ]
    }
  ]
}